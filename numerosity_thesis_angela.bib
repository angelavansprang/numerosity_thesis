
@article{richards_deep_2019,
	title = {A deep learning framework for neuroscience},
	volume = {22},
	copyright = {2019 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0520-2},
	doi = {10.1038/s41593-019-0520-2},
	abstract = {Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In artificial neural networks, the three components specified by design are the objective functions, the learning rules and the architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help to generate more rapid progress.},
	language = {en},
	number = {11},
	urldate = {2023-02-09},
	journal = {Nature Neuroscience},
	author = {Richards, Blake A. and Lillicrap, Timothy P. and Beaudoin, Philippe and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and Clopath, Claudia and Costa, Rui Ponte and de Berker, Archy and Ganguli, Surya and Gillon, Colleen J. and Hafner, Danijar and Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and Lindsay, Grace W. and Miller, Kenneth D. and Naud, Richard and Pack, Christopher C. and Poirazi, Panayiota and Roelfsema, Pieter and Sacramento, João and Saxe, Andrew and Scellier, Benjamin and Schapiro, Anna C. and Senn, Walter and Wayne, Greg and Yamins, Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien, Denis and Kording, Konrad P.},
	month = nov,
	year = {2019},
	note = {Number: 11
Publisher: Nature Publishing Group},
	keywords = {Learning algorithms, Machine learning, Neural circuits},
	pages = {1761--1770},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/ZPKQB5VA/Richards et al. - 2019 - A deep learning framework for neuroscience.pdf:application/pdf},
}

@misc{noauthor_three_nodate,
	title = {{THREE} {PARIETAL} {CIRCUITS} {FOR} {NUMBER} {PROCESSING}},
	url = {https://www.tandfonline.com/doi/epdf/10.1080/02643290244000239?needAccess=true&role=button},
	language = {en},
	urldate = {2023-02-09},
	doi = {10.1080/02643290244000239},
	file = {Snapshot:/Users/avansprang/Zotero/storage/MACN9GG6/02643290244000239.html:text/html;Submitted Version:/Users/avansprang/Zotero/storage/V7CDFCTN/THREE PARIETAL CIRCUITS FOR NUMBER PROCESSING.pdf:application/pdf},
}

@misc{noauthor_core_nodate,
	title = {Core systems of number},
	shorttitle = {doi},
	url = {https://reader.elsevier.com/reader/sd/pii/S1364661304001317?token=EAFD591B8729ADFBBBFFABC4E4858A51DFC65681091AD0AD030749A27409F25099367551F9591CC6581FB613D8E25DE2&originRegion=eu-west-1&originCreation=20230209105613},
	language = {en},
	urldate = {2023-02-09},
	doi = {10.1016/j.tics.2004.05.002},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/62LPDYUW/doi10.1016j.tics.2004.05.002  Elsevier Enhanced.pdf:application/pdf},
}

@misc{noauthor_abstract_nodate,
	title = {Abstract representations of numbers in the animal and human brain},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0166223698012636?token=D4BAA5276DD54C38907666D3260C3CF9158CD0A12B7D6BB383D63D764F31E2138E8AE32CE21FA9314073DA3A5424A7D3&originRegion=eu-west-1&originCreation=20230209104145},
	language = {en},
	urldate = {2023-02-09},
	doi = {10.1016/S0166-2236(98)01263-6},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/4B5YELSP/PII S0166-2236(98)01263-6  Elsevier Enhanced Rea.pdf:application/pdf},
}

@book{dehaene_number_1997,
	address = {New York},
	title = {The number sense: how the mind creates mathematics},
	isbn = {978-0-19-511004-3},
	shorttitle = {The number sense},
	language = {en},
	publisher = {Oxford University Press},
	author = {Dehaene, Stanislas},
	year = {1997},
	keywords = {Mathematical ability, Mathematics, Number concept, Study and teaching Psychological aspects},
	file = {Dehaene - 1997 - The number sense how the mind creates mathematics.pdf:/Users/avansprang/Zotero/storage/DV8QLMYA/Dehaene - 1997 - The number sense how the mind creates mathematics.pdf:application/pdf},
}

@misc{noauthor_does_nodate,
	title = {Does {Subitizing} {Reflect} {Numerical} {Estimation}?},
	url = {https://journals.sagepub.com/doi/epub/10.1111/j.1467-9280.2008.02130.x},
	language = {en},
	urldate = {2023-01-27},
	note = {ISSN: 1467-9280},
	file = {Snapshot:/Users/avansprang/Zotero/storage/4P7ATRP7/j.1467-9280.2008.02130.html:text/html},
}

@article{alberto_visual_2020,
	title = {Visual sense of number vs. sense of magnitude in humans and machines},
	volume = {10},
	copyright = {© The Author(s) 2020. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
	url = {https://www.proquest.com/docview/2415569336/abstract/EDD7928C1D264F9APQ/1},
	doi = {10.1038/s41598-020-66838-5},
	abstract = {Numerosity perception is thought to be foundational to mathematical learning, but its computational bases are strongly debated. Some investigators argue that humans are endowed with a specialized system supporting numerical representations; others argue that visual numerosity is estimated using continuous magnitudes, such as density or area, which usually co-vary with number. Here we reconcile these contrasting perspectives by testing deep neural networks on the same numerosity comparison task that was administered to human participants, using a stimulus space that allows the precise measurement of the contribution of non-numerical features. Our model accurately simulates the psychophysics of numerosity perception and the associated developmental changes: discrimination is driven by numerosity, but non-numerical features also have a significant impact, especially early during development. Representational similarity analysis further highlights that both numerosity and continuous magnitudes are spontaneously encoded in deep networks even when no task has to be carried out, suggesting that numerosity is a major, salient property of our visual environment.},
	language = {English},
	number = {1},
	urldate = {2023-01-27},
	journal = {Scientific Reports (Nature Publisher Group)},
	author = {Alberto, Testolin and Serena, Dolfi and Mathijs, Rochus and Zorzi, Marco},
	year = {2020},
	note = {Place: London, United States
Publisher: Nature Publishing Group},
	keywords = {Computer applications, Deep learning, Generalized linear models, Hypotheses, Neural networks, Perception, Psychophysics, Quantitative psychology, Sciences: Comprehensive Works, Simulation, Visual discrimination, Visual stimuli},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/5EEC3PG2/Alberto et al. - 2020 - Visual sense of number vs. sense of magnitude in h.pdf:application/pdf},
}

@article{testolin_numerosity_2020,
	title = {Numerosity discrimination in deep neural networks: {Initial} competence, developmental refinement and experience statistics},
	volume = {23},
	issn = {1467-7687},
	shorttitle = {Numerosity discrimination in deep neural networks},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12940},
	doi = {10.1111/desc.12940},
	abstract = {Both humans and non-human animals exhibit sensitivity to the approximate number of items in a visual array, as indexed by their performance in numerosity discrimination tasks, and even neonates can detect changes in numerosity. These findings are often interpreted as evidence for an innate ‘number sense’. However, recent simulation work has challenged this view by showing that human-like sensitivity to numerosity can emerge in deep neural networks that build an internal model of the sensory data. This emergentist perspective posits a central role for experience in shaping our number sense and might explain why numerical acuity progressively increases over the course of development. Here we substantiate this hypothesis by introducing a progressive unsupervised deep learning algorithm, which allows us to model the development of numerical acuity through experience. We also investigate how the statistical distribution of numerical and non-numerical features in natural environments affects the emergence of numerosity representations in the computational model. Our simulations show that deep networks can exhibit numerosity sensitivity prior to any training, as well as a progressive developmental refinement that is modulated by the statistical structure of the learning environment. To validate our simulations, we offer a refinement to the quantitative characterization of the developmental patterns observed in human children. Overall, our findings suggest that it may not be necessary to assume that animals are endowed with a dedicated system for processing numerosity, since domain-general learning mechanisms can capture key characteristics others have attributed to an evolutionarily specialized number system.},
	language = {en},
	number = {5},
	urldate = {2023-01-27},
	journal = {Developmental Science},
	author = {Testolin, Alberto and Zou, Will Y. and McClelland, James L.},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12940},
	keywords = {numerosity perception, deep neural networks, approximate number system, computational modeling, number sense development, visual number sense},
	pages = {e12940},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/PELVGS28/Testolin et al. - 2020 - Numerosity discrimination in deep neural networks.pdf:application/pdf;Snapshot:/Users/avansprang/Zotero/storage/MD53S3L7/desc.html:text/html},
}

@inproceedings{dahlgren_lindstrom_probing_2020,
	address = {Barcelona, Spain (Online)},
	title = {Probing {Multimodal} {Embeddings} for {Linguistic} {Properties}: the {Visual}-{Semantic} {Case}},
	shorttitle = {Probing {Multimodal} {Embeddings} for {Linguistic} {Properties}},
	url = {https://aclanthology.org/2020.coling-main.64},
	doi = {10.18653/v1/2020.coling-main.64},
	abstract = {Semantic embeddings have advanced the state of the art for countless natural language processing tasks, and various extensions to multimodal domains, such as visual-semantic embeddings, have been proposed. While the power of visual-semantic embeddings comes from the distillation and enrichment of information through machine learning, their inner workings are poorly understood and there is a shortage of analysis tools. To address this problem, we generalize the notion ofprobing tasks to the visual-semantic case. To this end, we (i) discuss the formalization of probing tasks for embeddings of image-caption pairs, (ii) define three concrete probing tasks within our general framework, (iii) train classifiers to probe for those properties, and (iv) compare various state-of-the-art embeddings under the lens of the proposed probing tasks. Our experiments reveal an up to 16\% increase in accuracy on visual-semantic embeddings compared to the corresponding unimodal embeddings, which suggest that the text and image dimensions represented in the former do complement each other.},
	urldate = {2023-01-26},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Dahlgren Lindström, Adam and Björklund, Johanna and Bensch, Suna and Drewes, Frank},
	month = dec,
	year = {2020},
	pages = {730--744},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/VDYB78EK/Dahlgren Lindström et al. - 2020 - Probing Multimodal Embeddings for Linguistic Prope.pdf:application/pdf},
}

@inproceedings{pezzelle_comparatives_2018,
	address = {New Orleans, Louisiana},
	title = {Comparatives, {Quantifiers}, {Proportions}: a {Multi}-{Task} {Model} for the {Learning} of {Quantities} from {Vision}},
	shorttitle = {Comparatives, {Quantifiers}, {Proportions}},
	url = {http://aclweb.org/anthology/N18-1039},
	doi = {10.18653/v1/N18-1039},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of            the {Association} for {Computational} {Linguistics}: {Human} {Language}            {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Pezzelle, Sandro and Sorodoc, Ionut-Teodor and Bernardi, Raffaella},
	year = {2018},
	pages = {419--430},
}

@inproceedings{parcalabescu_valse_2022,
	address = {Dublin, Ireland},
	title = {{VALSE}: {A} {Task}-{Independent} {Benchmark} for {Vision} and {Language} {Models} {Centered} on {Linguistic} {Phenomena}},
	shorttitle = {{VALSE}},
	url = {https://aclanthology.org/2022.acl-long.567},
	doi = {10.18653/v1/2022.acl-long.567},
	language = {en},
	urldate = {2023-01-23},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Parcalabescu, Letitia and Cafagna, Michele and Muradjan, Lilitta and Frank, Anette and Calixto, Iacer and Gatt, Albert},
	year = {2022},
	pages = {8253--8280},
}

@misc{hupkes_visualisation_2018,
	title = {Visualisation and 'diagnostic classifiers' reveal how recurrent and recursive neural networks process hierarchical structure},
	url = {http://arxiv.org/abs/1711.10203},
	abstract = {We investigate how neural networks can learn and process languages with hierarchical, compositional semantics. To this end, we define the artificial task of processing nested arithmetic expressions, and study whether different types of neural networks can learn to compute their meaning. We find that recursive neural networks can find a generalising solution to this problem, and we visualise this solution by breaking it up in three steps: project, sum and squash. As a next step, we investigate recurrent neural networks, and show that a gated recurrent unit, that processes its input incrementally, also performs very well on this task. To develop an understanding of what the recurrent network encodes, visualisation techniques alone do not suffice. Therefore, we develop an approach where we formulate and test multiple hypotheses on the information encoded and processed by the network. For each hypothesis, we derive predictions about features of the hidden state representations at each time step, and train 'diagnostic classifiers' to test those predictions. Our results indicate that the networks follow a strategy similar to our hypothesised 'cumulative strategy', which explains the high accuracy of the network on novel expressions, the generalisation to longer expressions than seen in training, and the mild deterioration with increasing length. This is turn shows that diagnostic classifiers can be a useful technique for opening up the black box of neural networks. We argue that diagnostic classification, unlike most visualisation techniques, does scale up from small networks in a toy domain, to larger and deeper recurrent networks dealing with real-life data, and may therefore contribute to a better understanding of the internal dynamics of current state-of-the-art models in natural language processing.},
	urldate = {2023-01-12},
	publisher = {arXiv},
	author = {Hupkes, Dieuwke and Veldhoen, Sara and Zuidema, Willem},
	month = apr,
	year = {2018},
	note = {arXiv:1711.10203 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/8MWTAL9L/Hupkes et al. - 2018 - Visualisation and 'diagnostic classifiers' reveal .pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/IJ39MXUT/1711.html:text/html},
}

@inproceedings{paul_vision_2022,
	title = {Vision {Transformers} {Are} {Robust} {Learners}},
	volume = {36},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/20103},
	doi = {10.1609/aaai.v36i2.20103},
	abstract = {Transformers, composed of multiple self-attention layers, hold strong promises toward a generic learning primitive applicable to different data modalities, including the recent breakthroughs in computer vision achieving state-of-the-art (SOTA) standard accuracy. What remains largely unexplored is their robustness evaluation and attribution. In this work, we study the robustness of the Vision Transformer (ViT) (Dosovitskiy et al. 2021) against common corruptions and perturbations, distribution shifts, and natural adversarial examples. We use six different diverse ImageNet datasets concerning robust classification to conduct a comprehensive performance comparison of ViT(Dosovitskiy et al. 2021) models and SOTA convolutional neural networks (CNNs), Big-Transfer (Kolesnikov et al. 2020). Through a series of six systematically designed experiments, we then present analyses that provide both quantitative andqualitative indications to explain why ViTs are indeed more robust learners. For example, with fewer parameters and similar dataset and pre-training combinations, ViT gives a top-1accuracy of 28.10\% on ImageNet-A which is 4.3x higher than a comparable variant of BiT. Our analyses on image masking, Fourier spectrum sensitivity, and spread on discrete cosine energy spectrum reveal intriguing properties of ViT attributing to improved robustness. Code for reproducing our experiments is available at https://git.io/J3VO0.},
	urldate = {2023-01-20},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Paul, Sayak and Chen, Pin-Yu},
	month = jun,
	year = {2022},
	note = {ISSN: 2374-3468, 2159-5399
Issue: 2
Journal Abbreviation: AAAI},
	pages = {2071--2081},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/79UHRGEN/Paul and Chen - 2022 - Vision Transformers Are Robust Learners.pdf:application/pdf},
}

@misc{alain_understanding_2018,
	title = {Understanding intermediate layers using linear classifier probes},
	url = {http://arxiv.org/abs/1610.01644},
	abstract = {Neural network models have a reputation for being black boxes. We propose to monitor the features at every layer of a model and measure how suitable they are for classification. We use linear classifiers, which we refer to as "probes", trained entirely independently of the model itself. This helps us better understand the roles and dynamics of the intermediate layers. We demonstrate how this can be used to develop a better intuition about models and to diagnose potential problems. We apply this technique to the popular models Inception v3 and Resnet-50. Among other things, we observe experimentally that the linear separability of features increase monotonically along the depth of the model.},
	urldate = {2023-01-12},
	publisher = {arXiv},
	author = {Alain, Guillaume and Bengio, Yoshua},
	month = nov,
	year = {2018},
	note = {arXiv:1610.01644 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/93PGXUC9/Alain and Bengio - 2018 - Understanding intermediate layers using linear cla.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/GA7F2HCQ/1610.html:text/html},
}

@misc{dewind_number_2019,
	title = {The number sense is an emergent property of a deep convolutional neural network trained for object recognition},
	url = {http://biorxiv.org/lookup/doi/10.1101/609347},
	doi = {10.1101/609347},
	abstract = {Summary
          
            Humans and many non-human animals have the “number sense,” an ability to estimate the number of items in a set without counting. This innate sense of number is hypothesized to provide a foundation for more complex numerical and mathematical concepts. Here I investigated whether we also share the number sense with a deep convolutional neural network (DCNN) trained for object recognition. These
            in silico
            networks have revolutionized machine learning over the last seven years, allowing computers to reach human-level performance on object recognition tasks for the first time. Their architecture is based on the structure of mammalian visual cortex, and after they are trained, they provide a highly predictive model of responses in primate visual cortex, suggesting deep homologies. I found that the DCNN demonstrates three key hallmarks of the number sense: numerosity-selective units (analogous to biological neurons), the behavioral ratio effect, and ordinality over representational space. Because the DCNN was not trained to enumerate, I conclude that the number sense is an emergent property of the network, the result of some combination of the network architecture and the constraint to develop the complex representational structure necessary for object recognition. By analogy I conclude that the number sense in animals was not necessarily the result of direct selective pressure to enumerate but might have “come for free” with the evolution of a complex visual system that evolved to identify objects and scenes in the real world.},
	language = {en},
	urldate = {2023-01-20},
	author = {DeWind, Nicholas K.},
	month = apr,
	year = {2019},
	doi = {10.1101/609347},
	note = {Institution: Animal Behavior and Cognition},
	file = {Submitted Version:/Users/avansprang/Zotero/storage/4SI2YN2J/DeWind - 2019 - The number sense is an emergent property of a deep.pdf:application/pdf},
}

@article{kajic_probing_nodate,
	title = {Probing {Representations} of {Numbers} in {Vision} and {Language} {Models}},
	abstract = {The ability to represent and reason about numbers in different contexts is an important aspect of human and animal cognition. Literature in numerical cognition posits the existence of two number representation systems: one for representing small, exact numbers, which is largely based on visual processing, and another system for representing larger, approximate quantities. In this work, we investigate number sense in vision and language models by examining learned representations and asking: What is the structure of the space representing numbers? Which modality contributes mostly to the representation of a number? While our analyses reveal that small numbers are processed differently from large numbers, as in biological systems, we also found a strong linguistic contribution in the structure of number representations in vision and language models, highlighting a difference between representations in biology and artificial systems.},
	language = {en},
	author = {Kajic, Ivana and Nematzadeh, Aida},
	file = {Kajic and Nematzadeh - Probing Representations of Numbers in Vision and L.pdf:/Users/avansprang/Zotero/storage/GWFZTIJY/Kajic and Nematzadeh - Probing Representations of Numbers in Vision and L.pdf:application/pdf},
}

@inproceedings{parfenova_probing_2021,
	address = {Online},
	title = {Probing {Cross}-{Modal} {Representations} in {Multi}-{Step} {Relational} {Reasoning}},
	url = {https://aclanthology.org/2021.repl4nlp-1.16},
	doi = {10.18653/v1/2021.repl4nlp-1.16},
	abstract = {We investigate the representations learned by vision and language models in tasks that require relational reasoning. Focusing on the problem of assessing the relative size of objects in abstract visual contexts, we analyse both one-step and two-step reasoning. For the latter, we construct a new dataset of three-image scenes and define a task that requires reasoning at the level of the individual images and across images in a scene. We probe the learned model representations using diagnostic classifiers. Our experiments show that pretrained multimodal transformer-based architectures can perform higher-level relational reasoning, and are able to learn representations for novel tasks and data that are very different from what was seen in pretraining.},
	urldate = {2022-11-29},
	booktitle = {Proceedings of the 6th {Workshop} on {Representation} {Learning} for {NLP} ({RepL4NLP}-2021)},
	publisher = {Association for Computational Linguistics},
	author = {Parfenova, Iuliia and Elliott, Desmond and Fernández, Raquel and Pezzelle, Sandro},
	month = aug,
	year = {2021},
	pages = {152--162},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/TXI2CXXL/Parfenova et al. - 2021 - Probing Cross-Modal Representations in Multi-Step .pdf:application/pdf},
}

@article{testolin_perception_nodate,
	title = {Perception of visual numerosity in humans and machines},
	abstract = {Numerosity perception is foundational to mathematical learning, but its computational bases are strongly debated. Some investigators argue that humans are endowed with a specialized system supporting numerical representation; others argue that visual numerosity is estimated using continuous magnitudes, such as density or area, which usually co-vary with number. Here we reconcile these contrasting perspectives by testing deep networks on the same numerosity comparison task that was administered to humans, using a stimulus space that allows to measure the contribution of nonnumerical features. Our model accurately simulated the psychophysics of numerosity perception and the associated developmental changes: discrimination was driven by numerosity information, but nonnumerical features had a significant impact, especially early during development. Representational similarity analysis further highlighted that both numerosity and continuous magnitudes were spontaneously encoded even when no task had to be carried out, demonstrating that numerosity is a major, salient property of our visual environment.},
	language = {en},
	author = {Testolin, Alberto and Dolfi, Serena and Rochus, Mathijs and Zorzi, Marco},
	file = {Testolin et al. - Perception of visual numerosity in humans and mach.pdf:/Users/avansprang/Zotero/storage/M7A953XH/Testolin et al. - Perception of visual numerosity in humans and mach.pdf:application/pdf},
}

@misc{geigle_one_2022,
	title = {One does not fit all! {On} the {Complementarity} of {Vision} {Encoders} for {Vision} and {Language} {Tasks}},
	url = {http://arxiv.org/abs/2210.06379},
	abstract = {Current multimodal models, aimed at solving Vision and Language (V+L) tasks, predominantly repurpose Vision Encoders (VE) as feature extractors. While many VEs -- of different architectures, trained on different data and objectives -- are publicly available, they are not designed for the downstream V+L tasks. Nonetheless, most current work assumes that a {\textbackslash}textit\{single\} pre-trained VE can serve as a general-purpose encoder. In this work, we evaluate whether the information stored within different VEs is complementary, i.e. if providing the model with features from multiple VEs can improve the performance on a target task. We exhaustively experiment with three popular VEs on six downstream V+L tasks and analyze the attention and VE-dropout patterns. Our results and analyses suggest that diverse VEs complement each other, resulting in improved downstream V+L task performance, where the improvements are not due to simple ensemble effects (i.e. the performance does not always improve when increasing the number of encoders). We demonstrate that future VEs, which are not {\textbackslash}textit\{repurposed\}, but explicitly {\textbackslash}textit\{designed\} for V+L tasks, have the potential of improving performance on the target V+L tasks.},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Geigle, Gregor and Liu, Chen and Pfeiffer, Jonas and Gurevych, Iryna},
	month = oct,
	year = {2022},
	note = {arXiv:2210.06379 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/DLF7JJS4/Geigle et al. - 2022 - One does not fit all! On the Complementarity of Vi.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/RNLBZW8W/2210.html:text/html},
}

@article{nasr_number_2019,
	title = {Number detectors spontaneously emerge in a deep neural network designed for visual object recognition},
	volume = {5},
	url = {https://www.science.org/doi/10.1126/sciadv.aav7903},
	doi = {10.1126/sciadv.aav7903},
	abstract = {Humans and animals have a “number sense,” an innate capability to intuitively assess the number of visual items in a set, its numerosity. This capability implies that mechanisms to extract numerosity indwell the brain’s visual system, which is primarily concerned with visual object recognition. Here, we show that network units tuned to abstract numerosity, and therefore reminiscent of real number neurons, spontaneously emerge in a biologically inspired deep neural network that was merely trained on visual object recognition. These numerosity-tuned units underlay the network’s number discrimination performance that showed all the characteristics of human and animal number discriminations as predicted by the Weber-Fechner law. These findings explain the spontaneous emergence of the number sense based on mechanisms inherent to the visual system.},
	number = {5},
	urldate = {2023-01-20},
	journal = {Science Advances},
	author = {Nasr, Khaled and Viswanathan, Pooja and Nieder, Andreas},
	month = may,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaav7903},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/BNM6C22X/Nasr et al. - 2019 - Number detectors spontaneously emerge in a deep ne.pdf:application/pdf},
}

@misc{akkus_multimodal_2023,
	title = {Multimodal {Deep} {Learning}},
	url = {http://arxiv.org/abs/2301.04856},
	doi = {10.48550/arXiv.2301.04856},
	abstract = {This book is the result of a seminar in which we reviewed multimodal approaches and attempted to create a solid overview of the field, starting with the current state-of-the-art approaches in the two subfields of Deep Learning individually. Further, modeling frameworks are discussed where one modality is transformed into the other, as well as models in which one modality is utilized to enhance representation learning for the other. To conclude the second part, architectures with a focus on handling both modalities simultaneously are introduced. Finally, we also cover other modalities as well as general-purpose multi-modal models, which are able to handle different tasks on different modalities within one unified architecture. One interesting application (Generative Art) eventually caps off this booklet.},
	urldate = {2023-01-13},
	publisher = {arXiv},
	author = {Akkus, Cem and Chu, Luyang and Djakovic, Vladana and Jauch-Walser, Steffen and Koch, Philipp and Loss, Giacomo and Marquardt, Christopher and Moldovan, Marco and Sauter, Nadja and Schneider, Maximilian and Schulte, Rickmer and Urbanczyk, Karol and Goschenhofer, Jann and Heumann, Christian and Hvingelby, Rasmus and Schalk, Daniel and Aßenmacher, Matthias},
	month = jan,
	year = {2023},
	note = {arXiv:2301.04856 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/NJZJN7XD/Akkus et al. - 2023 - Multimodal Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/QL9SFHXL/2301.html:text/html},
}

@misc{zhang_learning_2018,
	title = {Learning to {Count} {Objects} in {Natural} {Images} for {Visual} {Question} {Answering}},
	url = {http://arxiv.org/abs/1802.05766},
	abstract = {Visual Question Answering (VQA) models have struggled with counting objects in natural images so far. We identify a fundamental problem due to soft attention in these models as a cause. To circumvent this problem, we propose a neural network component that allows robust counting from object proposals. Experiments on a toy task show the effectiveness of this component and we obtain state-of-the-art accuracy on the number category of the VQA v2 dataset without negatively affecting other categories, even outperforming ensemble models with our single model. On a difficult balanced pair metric, the component gives a substantial improvement in counting over a strong baseline by 6.6\%.},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Zhang, Yan and Hare, Jonathon and Prügel-Bennett, Adam},
	month = feb,
	year = {2018},
	note = {arXiv:1802.05766 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/7QMLPYDG/Zhang et al. - 2018 - Learning to Count Objects in Natural Images for Vi.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/VUMXCEEC/1802.html:text/html},
}

@misc{zhang_numerosity_2020,
	title = {On {Numerosity} of {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2011.08674},
	doi = {10.48550/arXiv.2011.08674},
	abstract = {Recently, a provocative claim was published that number sense spontaneously emerges in a deep neural network trained merely for visual object recognition. This has, if true, far reaching significance to the fields of machine learning and cognitive science alike. In this paper, we prove the above claim to be unfortunately incorrect. The statistical analysis to support the claim is flawed in that the sample set used to identify number-aware neurons is too small, compared to the huge number of neurons in the object recognition network. By this flawed analysis one could mistakenly identify number-sensing neurons in any randomly initialized deep neural networks that are not trained at all. With the above critique we ask the question what if a deep convolutional neural network is carefully trained for numerosity? Our findings are mixed. Even after being trained with number-depicting images, the deep learning approach still has difficulties to acquire the abstract concept of numbers, a cognitive task that preschoolers perform with ease. But on the other hand, we do find some encouraging evidences suggesting that deep neural networks are more robust to distribution shift for small numbers than for large numbers.},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Zhang, Xi and Wu, Xiaolin},
	month = nov,
	year = {2020},
	note = {arXiv:2011.08674 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/HCS9WZT4/Zhang and Wu - 2020 - On Numerosity of Deep Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/R63CMZ7X/2011.html:text/html},
}

@misc{nogueira_investigating_2021,
	title = {Investigating the {Limitations} of {Transformers} with {Simple} {Arithmetic} {Tasks}},
	url = {http://arxiv.org/abs/2102.13019},
	abstract = {The ability to perform arithmetic tasks is a remarkable trait of human intelligence and might form a critical component of more complex reasoning tasks. In this work, we investigate if the surface form of a number has any influence on how sequence-to-sequence language models learn simple arithmetic tasks such as addition and subtraction across a wide range of values. We find that how a number is represented in its surface form has a strong influence on the model's accuracy. In particular, the model fails to learn addition of five-digit numbers when using subwords (e.g., "32"), and it struggles to learn with character-level representations (e.g., "3 2"). By introducing position tokens (e.g., "3 10e1 2"), the model learns to accurately add and subtract numbers up to 60 digits. We conclude that modern pretrained language models can easily learn arithmetic from very few examples, as long as we use the proper surface representation. This result bolsters evidence that subword tokenizers and positional encodings are components in current transformer designs that might need improvement. Moreover, we show that regardless of the number of parameters and training examples, models cannot learn addition rules that are independent of the length of the numbers seen during training. Code to reproduce our experiments is available at https://github.com/castorini/transformers-arithmetic},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Nogueira, Rodrigo and Jiang, Zhiying and Lin, Jimmy},
	month = apr,
	year = {2021},
	note = {arXiv:2102.13019 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/8TSEWJRI/Nogueira et al. - 2021 - Investigating the Limitations of Transformers with.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/823BLFMR/2102.html:text/html},
}

@article{boccato_learning_2021,
	title = {Learning {Numerosity} {Representations} with {Transformers}: {Number} {Generation} {Tasks} and {Out}-of-{Distribution} {Generalization}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	shorttitle = {Learning {Numerosity} {Representations} with {Transformers}},
	url = {https://www.mdpi.com/1099-4300/23/7/857},
	doi = {10.3390/e23070857},
	abstract = {One of the most rapidly advancing areas of deep learning research aims at creating models that learn to disentangle the latent factors of variation from a data distribution. However, modeling joint probability mass functions is usually prohibitive, which motivates the use of conditional models assuming that some information is given as input. In the domain of numerical cognition, deep learning architectures have successfully demonstrated that approximate numerosity representations can emerge in multi-layer networks that build latent representations of a set of images with a varying number of items. However, existing models have focused on tasks requiring to conditionally estimate numerosity information from a given image. Here, we focus on a set of much more challenging tasks, which require to conditionally generate synthetic images containing a given number of items. We show that attention-based architectures operating at the pixel level can learn to produce well-formed images approximately containing a specific number of items, even when the target numerosity was not present in the training distribution.},
	language = {en},
	number = {7},
	urldate = {2023-01-20},
	journal = {Entropy},
	author = {Boccato, Tommaso and Testolin, Alberto and Zorzi, Marco},
	month = jul,
	year = {2021},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {numerosity perception, attention mechanisms, cognitive modeling, deep neural networks, density estimation},
	pages = {857},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/99UACV2Z/Boccato et al. - 2021 - Learning Numerosity Representations with Transform.pdf:application/pdf},
}

@misc{wei_emergent_2022,
	title = {Emergent {Abilities} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2206.07682},
	abstract = {Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and Chi, Ed H. and Hashimoto, Tatsunori and Vinyals, Oriol and Liang, Percy and Dean, Jeff and Fedus, William},
	month = oct,
	year = {2022},
	note = {arXiv:2206.07682 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/6DGQDTSZ/Wei et al. - 2022 - Emergent Abilities of Large Language Models.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/L7KAL2C3/2206.html:text/html},
}

@article{stoianov_emergence_2012,
	title = {Emergence of a 'visual number sense' in hierarchical generative models},
	volume = {15},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/nn.2996},
	doi = {10.1038/nn.2996},
	abstract = {Numerosity estimation is phylogenetically ancient and foundational to human mathematical learning, but its computational bases remain controversial. Here we show that visual numerosity emerges as a statistical property of images in 'deep networks' that learn a hierarchical generative model of the sensory input. Emergent numerosity detectors had response profiles resembling those of monkey parietal neurons and supported numerosity estimation with the same behavioral signature shown by humans and animals.},
	language = {en},
	number = {2},
	urldate = {2023-01-20},
	journal = {Nature Neuroscience},
	author = {Stoianov, Ivilin and Zorzi, Marco},
	month = feb,
	year = {2012},
	pages = {194--196},
	file = {Full Text:/Users/avansprang/Zotero/storage/QZ6SMWZM/Stoianov and Zorzi - 2012 - Emergence of a 'visual number sense' in hierarchic.pdf:application/pdf},
}

@article{zorzi_emergentist_2018,
	title = {An emergentist perspective on the origin of number sense},
	volume = {373},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2017.0043},
	doi = {10.1098/rstb.2017.0043},
	abstract = {The finding that human infants and many other animal species are sensitive to numerical quantity has been widely interpreted as evidence for evolved, biologically determined numerical capacities across unrelated species, thereby supporting a ‘nativist’ stance on the origin of number sense. Here, we tackle this issue within the ‘emergentist’ perspective provided by artificial neural network models, and we build on computer simulations to discuss two different approaches to think about the innateness of number sense. The first, illustrated by artificial life simulations, shows that numerical abilities can be supported by domain-specific representations emerging from evolutionary pressure. The second assumes that numerical representations need not be genetically pre-determined but can emerge from the interplay between innate architectural constraints and domain-general learning mechanisms, instantiated in deep learning simulations. We show that deep neural networks endowed with basic visuospatial processing exhibit a remarkable performance in numerosity discrimination before any experience-dependent learning, whereas unsupervised sensory experience with visual sets leads to subsequent improvement of number acuity and reduces the influence of continuous visual cues. The emergent neuronal code for numbers in the model includes both numerosity-sensitive (summation coding) and numerosity-selective response profiles, closely mirroring those found in monkey intraparietal neurons. We conclude that a form of innatism based on architectural and learning biases is a fruitful approach to understanding the origin and development of number sense.

This article is part of a discussion meeting issue ‘The origins of numerical abilities'.},
	number = {1740},
	urldate = {2023-01-20},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Zorzi, Marco and Testolin, Alberto},
	month = jan,
	year = {2018},
	note = {Publisher: Royal Society},
	keywords = {artificial neural networks, computational modelling, deep learning, number sense, numerical development, numerosity perception},
	pages = {20170043},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/ZKUNVH79/Zorzi and Testolin - 2018 - An emergentist perspective on the origin of number.pdf:application/pdf},
}

@misc{burns_discovering_2022,
	title = {Discovering {Latent} {Knowledge} in {Language} {Models} {Without} {Supervision}},
	url = {http://arxiv.org/abs/2212.03827},
	doi = {10.48550/arXiv.2212.03827},
	abstract = {Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4{\textbackslash}\% on average. We also find that it cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don't have access to explicit ground truth labels.},
	urldate = {2023-01-13},
	publisher = {arXiv},
	author = {Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
	month = dec,
	year = {2022},
	note = {arXiv:2212.03827 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/3RRYXN9Q/Burns et al. - 2022 - Discovering Latent Knowledge in Language Models Wi.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/FIBHNUYE/2212.html:text/html},
}

@article{salin_are_2022,
	title = {Are {Vision}-{Language} {Transformers} {Learning} {Multimodal} {Representations}? {A} {Probing} {Perspective}},
	volume = {36},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {Are {Vision}-{Language} {Transformers} {Learning} {Multimodal} {Representations}?},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/21375},
	doi = {10.1609/aaai.v36i10.21375},
	abstract = {In recent years, joint text-image embeddings have significantly improved thanks to the development of transformer-based Vision-Language models. Despite these advances, we still need to better understand the representations produced by those models. In this paper, we compare pre-trained and fine-tuned representations at a vision, language and multimodal level. To that end, we use a set of probing tasks to evaluate the performance of state-of-the-art Vision-Language models and introduce new datasets specifically for multimodal probing. These datasets are carefully designed to address a range of multimodal capabilities while minimizing the potential for models to rely on bias. Although the results confirm the ability of Vision-Language models to understand color at a multimodal level, the models seem to prefer relying on bias in text data for object position and size. On semantically adversarial examples, we find that those models are able to pinpoint fine-grained multimodal differences. Finally, we also notice that fine-tuning a Vision-Language model on multimodal tasks does not necessarily improve its multimodal ability. We make all datasets and code available to replicate experiments.},
	language = {en},
	number = {10},
	urldate = {2023-01-20},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Salin, Emmanuelle and Farah, Badreddine and Ayache, Stéphane and Favre, Benoit},
	month = jun,
	year = {2022},
	note = {Number: 10},
	keywords = {Machine Learning (ML), related\_work},
	pages = {11248--11257},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/5V8YNS7V/Salin et al. - 2022 - Are Vision-Language Transformers Learning Multimod.pdf:application/pdf},
}

@article{zhang_diagnosing_2023,
	title = {{DIAGNOSING} {AND} {RECTIFYING} {VISION} {MODELS} {USING} {LANGUAGE}},
	abstract = {Recent multi-modal contrastive learning models have demonstrated the ability to learn an embedding space suitable for building strong vision classifiers, by leveraging the rich information in large-scale image-caption datasets. Our work highlights a distinct advantage of this multi-modal embedding space: the ability to diagnose vision classifiers through natural language. The traditional process of diagnosing model behaviors in deployment settings involves labor-intensive data acquisition and annotation. Our proposed method can discover high-error data slices, identify influential attributes and further rectify undesirable model behaviors, without requiring any visual data. Through a combination of theoretical explanation and empirical verification, we present conditions under which classifiers trained on embeddings from one modality can be equivalently applied to embeddings from another modality. On a range of image datasets with known error slices, we demonstrate that our method can effectively identify the error slices and influential attributes, and can further use language to rectify failure modes of the classifier.},
	language = {en},
	author = {Zhang, Yuhui and HaoChen, Jeff Z and Huang, Shih-Cheng and Wang, Kuan-Chieh and Zou, James and Yeung, Serena},
	year = {2023},
	file = {Zhang et al. - 2023 - DIAGNOSING AND RECTIFYING VISION MODELS USING LANG.pdf:/Users/avansprang/Zotero/storage/T3PU9MGV/Zhang et al. - 2023 - DIAGNOSING AND RECTIFYING VISION MODELS USING LANG.pdf:application/pdf},
}

@misc{ravfogel_kernelized_2022,
	title = {Kernelized {Concept} {Erasure}},
	url = {http://arxiv.org/abs/2201.12191},
	abstract = {The representation space of neural models for textual data emerges in an unsupervised manner during training. Understanding how those representations encode human-interpretable concepts is a fundamental problem. One prominent approach for the identification of concepts in neural representations is searching for a linear subspace whose erasure prevents the prediction of the concept from the representations. However, while many linear erasure algorithms are tractable and interpretable, neural networks do not necessarily represent concepts in a linear manner. To identify non-linearly encoded concepts, we propose a kernelization of a linear minimax game for concept erasure. We demonstrate that it is possible to prevent specific non-linear adversaries from predicting the concept. However, the protection does not transfer to different nonlinear adversaries. Therefore, exhaustively erasing a non-linearly encoded concept remains an open problem.},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Ravfogel, Shauli and Vargas, Francisco and Goldberg, Yoav and Cotterell, Ryan},
	month = dec,
	year = {2022},
	note = {arXiv:2201.12191 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/QFNLGREM/Ravfogel et al. - 2022 - Kernelized Concept Erasure.pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/LP3D5EH8/2201.html:text/html},
}

@misc{li_blip-2_2023,
	title = {{BLIP}-2: {Bootstrapping} {Language}-{Image} {Pre}-training with {Frozen} {Image} {Encoders} and {Large} {Language} {Models}},
	shorttitle = {{BLIP}-2},
	url = {http://arxiv.org/abs/2301.12597},
	abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
	month = jan,
	year = {2023},
	note = {arXiv:2301.12597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/avansprang/Zotero/storage/JVP88B6T/Li et al. - 2023 - BLIP-2 Bootstrapping Language-Image Pre-training .pdf:application/pdf;arXiv.org Snapshot:/Users/avansprang/Zotero/storage/PGIKZ9CL/2301.html:text/html},
}

@inproceedings{xu_explainable_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Explainable {AI}: {A} {Brief} {Survey} on {History}, {Research} {Areas}, {Approaches} and {Challenges}},
	isbn = {978-3-030-32236-6},
	shorttitle = {Explainable {AI}},
	doi = {10.1007/978-3-030-32236-6_51},
	abstract = {Deep learning has made significant contribution to the recent progress in artificial intelligence. In comparison to traditional machine learning methods such as decision trees and support vector machines, deep learning methods have achieved substantial improvement in various prediction tasks. However, deep neural networks (DNNs) are comparably weak in explaining their inference processes and final results, and they are typically treated as a black-box by both developers and users. Some people even consider DNNs (deep neural networks) in the current stage rather as alchemy, than as real science. In many real-world applications such as business decision, process optimization, medical diagnosis and investment recommendation, explainability and transparency of our AI systems become particularly essential for their users, for the people who are affected by AI decisions, and furthermore, for the researchers and developers who create the AI solutions. In recent years, the explainability and explainable AI have received increasing attention by both research community and industry. This paper first introduces the history of Explainable AI, starting from expert systems and traditional machine learning approaches to the latest progress in the context of modern deep learning, and then describes the major research areas and the state-of-art approaches in recent years. The paper ends with a discussion on the challenges and future directions.},
	language = {en},
	booktitle = {Natural {Language} {Processing} and {Chinese} {Computing}},
	publisher = {Springer International Publishing},
	author = {Xu, Feiyu and Uszkoreit, Hans and Du, Yangzhou and Fan, Wei and Zhao, Dongyan and Zhu, Jun},
	editor = {Tang, Jie and Kan, Min-Yen and Zhao, Dongyan and Li, Sujian and Zan, Hongying},
	year = {2019},
	keywords = {Explainable artificial intelligence, Explainable interfaces, Intelligible machine learning, Interpretability, XAI},
	pages = {563--574},
	file = {Full Text PDF:/Users/avansprang/Zotero/storage/9GM97CHA/Xu et al. - 2019 - Explainable AI A Brief Survey on History, Researc.pdf:application/pdf},
}

@article{nieder_labeled-line_2007,
	title = {A {Labeled}-{Line} {Code} for {Small} and {Large} {Numerosities} in the {Monkey} {Prefrontal} {Cortex}},
	volume = {27},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1056-07.2007},
	doi = {10.1523/JNEUROSCI.1056-07.2007},
	abstract = {How single neurons represent information about the magnitude of a stimulus remains controversial. Neurons encoding purely sensory magnitude typically show monotonic response functions (“summation coding”), and summation units are usually implemented in models of numerosity representation. In contrast, cells representing numerical quantity exhibit nonmonotonic tuning functions that peak at their preferred numerosity (“labeled-line code”), but the restricted range of tested quantities in these studies did not permit a definite answer. Here, we analyzed both behavioral and neuronal representations of a broad range of numerosities from 1 to 30 in the prefrontal cortex of monkeys. Numerosity-selective neurons showed a clear and behaviorally relevant labeled-line code for all numerosities. Moreover, both the behavioral and neuronal tuning functions obeyed the Weber–Fechner Law and were best represented on a nonlinearly compressed scale. Our single-cell study is in good agreement with functional imaging data reporting peaked tuning functions in humans, demonstrating neuronal precursors for human number competence in a nonhuman primate. Our findings also emphasize that the manner in which neurons encode and maintain magnitude information may depend on the precise task at hand as well as the type of magnitude to represent and memorize.},
	language = {en},
	number = {22},
	urldate = {2023-02-24},
	journal = {The Journal of Neuroscience},
	author = {Nieder, Andreas and Merten, Katharina},
	month = may,
	year = {2007},
	pages = {5986--5993},
	file = {Nieder and Merten - 2007 - A Labeled-Line Code for Small and Large Numerositi.pdf:/Users/avansprang/Zotero/storage/B9DFWWXY/Nieder and Merten - 2007 - A Labeled-Line Code for Small and Large Numerositi.pdf:application/pdf},
}

@book{arbib_handbook_2003,
	address = {Cambridge, Mass},
	edition = {2nd ed},
	title = {The handbook of brain theory and neural networks},
	isbn = {978-0-262-01197-6},
	language = {en},
	publisher = {MIT Press},
	editor = {Arbib, Michael A.},
	year = {2003},
	keywords = {Handbooks, manuals, etc, Neural networks (Computer science), Neural networks (Neurobiology)},
	file = {Arbib - 2003 - The handbook of brain theory and neural networks.pdf:/Users/avansprang/Zotero/storage/DM7LKLIC/Arbib - 2003 - The handbook of brain theory and neural networks.pdf:application/pdf},
}

@article{mandler_subitizing_nodate,
	title = {Subitizing: {An} {Analysis} of {Its} {Component} {Processes}},
	abstract = {The term subitizing was coined by Kaufman, Lord, Reese, and Volkmann in 1949 to describe the rapid, confident, and accurate report of the numerosity of arrays of elements presented for short durations. They noted that this process, different from counting and estimating, was restricted to arrays with 6 or fewer elements. Ever since the general awareness of some such process in the nineteenth century, the phenomenon has been a benchmark for the limited capacity of human consciousness, Previous research, as well as the data in these experiments, shows that the reaction time function for different arrays (ranging in size from 1 to 15) has a shallow slope for arrays with 1 to 3 elements followed by a straight line slope for arrays of 4 to 6 or 7, at which point the reaction time discontinuity typically occurs; reaction times then stay fairly constant as the array size increases, and the numerosity response becomes much less accurate. When the array is exposed for unlimited presentation time, the reaction time slope is a straight line from size 4 to as large as 30 or 40. In the latter case, subjects are clearly counting the array.},
	language = {en},
	author = {Mandler, George and Shebo, Billie Jo},
	file = {Mandler and Shebo - Subitizing An Analysis of Its Component Processes.pdf:/Users/avansprang/Zotero/storage/ALMJ2P99/Mandler and Shebo - Subitizing An Analysis of Its Component Processes.pdf:application/pdf},
}
